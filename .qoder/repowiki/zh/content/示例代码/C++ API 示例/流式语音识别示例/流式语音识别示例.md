# 流式语音识别示例

<cite>
**本文档中引用的文件**  
- [streaming-zipformer-cxx-api.cc](file://cxx-api-examples/streaming-zipformer-cxx-api.cc)
- [streaming-zipformer-rtf-cxx-api.cc](file://cxx-api-examples/streaming-zipformer-rtf-cxx-api.cc)
- [streaming-t-one-ctc-cxx-api.cc](file://cxx-api-examples/streaming-t-one-ctc-cxx-api.cc)
- [wenet-ctc-simulate-streaming-microphone-cxx-api.cc](file://cxx-api-examples/wenet-ctc-simulate-streaming-microphone-cxx-api.cc)
- [sense-voice-simulate-streaming-alsa-cxx-api.cc](file://cxx-api-examples/sense-voice-simulate-streaming-alsa-cxx-api.cc)
- [zipformer-ctc-simulate-streaming-alsa-cxx-api.cc](file://cxx-api-examples/zipformer-ctc-simulate-streaming-alsa-cxx-api.cc)
- [zipformer-transducer-simulate-streaming-microphone-cxx-api.cc](file://cxx-api-examples/zipformer-transducer-simulate-streaming-microphone-cxx-api.cc)
- [sense-voice-simulate-streaming-microphone-cxx-api.cc](file://cxx-api-examples/sense-voice-simulate-streaming-microphone-cxx-api.cc)
- [zipformer-ctc-simulate-streaming-microphone-cxx-api.cc](file://cxx-api-examples/zipformer-ctc-simulate-streaming-microphone-cxx-api.cc)
- [streaming-zipformer-with-hr-cxx-api.cc](file://cxx-api-examples/streaming-zipformer-with-hr-cxx-api.cc)
- [sherpa-onnx/c-api/cxx-api.h](file://sherpa-onnx/c-api/cxx-api.h)
</cite>

## 目录
1. [简介](#简介)
2. [核心API组件](#核心api组件)
3. [流式识别模型配置](#流式识别模型配置)
4. [音频流处理流程](#音频流处理流程)
5. [基于Zipformer的流式识别](#基于zipformer的流式识别)
6. [基于T-One CTC的流式识别](#基于t-one-ctc的流式识别)
7. [基于Wenet CTC的流式识别](#基于wenet-ctc的流式识别)
8. [基于SenseVoice的流式识别](#基于sensevoice的流式识别)
9. [使用ALSA和麦克风的模拟流式处理](#使用alsa和麦克风的模拟流式处理)
10. [实时因子(RTF)计算与监控](#实时因子rtf计算与监控)
11. [上下文管理与状态同步](#上下文管理与状态同步)

## 简介
sherpa-onnx提供了丰富的C++ API示例，用于实现流式自动语音识别(ASR)功能。这些示例涵盖了多种先进的语音识别模型，包括基于Zipformer CTC、Zipformer Transducer、T-One CTC、Wenet CTC和SenseVoice的流式识别系统。本文档深入解析这些示例代码，详细说明OnlineRecognizer和OnlineStream类的使用方法，如何配置OnlineModelConfig，以及如何分块处理音频流以实现低延迟识别。

**Section sources**
- [streaming-zipformer-cxx-api.cc](file://cxx-api-examples/streaming-zipformer-cxx-api.cc#L1-L94)
- [streaming-t-one-ctc-cxx-api.cc](file://cxx-api-examples/streaming-t-one-ctc-cxx-api.cc#L1-L90)

## 核心API组件

### OnlineRecognizer类
OnlineRecognizer是sherpa-onnx流式语音识别的核心类，负责管理识别器的生命周期和识别过程。通过OnlineRecognizer::Create静态方法创建实例，需要传入OnlineRecognizerConfig配置对象。

```mermaid
flowchart TD
A[创建OnlineRecognizerConfig] --> B[配置模型路径]
B --> C[设置线程数]
C --> D[创建OnlineRecognizer]
D --> E[创建OnlineStream]
E --> F[接受音频数据]
F --> G[解码识别]
G --> H[获取识别结果]
```

**Diagram sources**
- [streaming-zipformer-cxx-api.cc](file://cxx-api-examples/streaming-zipformer-cxx-api.cc#L24-L52)
- [streaming-t-one-ctc-cxx-api.cc](file://cxx-api-examples/streaming-t-one-ctc-cxx-api.cc#L24-L36)

### OnlineStream类
OnlineStream代表一个独立的音频流识别会话，用于处理单个音频流的识别任务。每个流式识别任务都需要创建一个OnlineStream实例。

```mermaid
sequenceDiagram
participant 应用程序
participant OnlineRecognizer
participant OnlineStream
应用程序->>OnlineRecognizer : CreateStream()
OnlineRecognizer-->>应用程序 : 返回OnlineStream
应用程序->>OnlineStream : AcceptWaveform()
应用程序->>OnlineStream : InputFinished()
应用程序->>OnlineRecognizer : IsReady()
OnlineRecognizer-->>应用程序 : true/false
应用程序->>OnlineRecognizer : Decode()
应用程序->>OnlineRecognizer : GetResult()
OnlineRecognizer-->>应用程序 : 识别结果
```

**Diagram sources**
- [streaming-zipformer-cxx-api.cc](file://cxx-api-examples/streaming-zipformer-cxx-api.cc#L66-L75)
- [streaming-t-one-ctc-cxx-api.cc](file://cxx-api-examples/streaming-t-one-ctc-cxx-api.cc#L55-L71)

**Section sources**
- [streaming-zipformer-cxx-api.cc](file://cxx-api-examples/streaming-zipformer-cxx-api.cc#L66-L75)
- [streaming-t-one-ctc-cxx-api.cc](file://cxx-api-examples/streaming-t-one-ctc-cxx-api.cc#L55-L71)

## 流式识别模型配置

### OnlineModelConfig配置
OnlineModelConfig用于配置流式识别模型的各种参数，包括模型路径、线程数、推理提供程序等。

```mermaid
classDiagram
class OnlineRecognizerConfig {
+ModelConfig model_config
+HotwordsConfig hotwords_config
+EndpointConfig endpoint_config
+HypothesesRescoringConfig hr
}
class ModelConfig {
+string transducer.encoder
+string transducer.decoder
+string transducer.joiner
+string zipformer_ctc.model
+string t_one_ctc.model
+string sense_voice.model
+string tokens
+int32_t num_threads
+string provider
+bool debug
}
class HotwordsConfig {
+string hotwords_file
+float scale
}
class EndpointConfig {
+float rule1_min_trailing_silence
+float rule2_min_trailing_silence
+float rule3_min_utterance_length
}
OnlineRecognizerConfig --> ModelConfig : "包含"
OnlineRecognizerConfig --> HotwordsConfig : "包含"
OnlineRecognizerConfig --> EndpointConfig : "包含"
OnlineRecognizerConfig --> HypothesesRescoringConfig : "包含"
```

**Diagram sources**
- [streaming-zipformer-cxx-api.cc](file://cxx-api-examples/streaming-zipformer-cxx-api.cc#L24-L44)
- [streaming-zipformer-rtf-cxx-api.cc](file://cxx-api-examples/streaming-zipformer-rtf-cxx-api.cc#L52-L73)
- [streaming-t-one-ctc-cxx-api.cc](file://cxx-api-examples/streaming-t-one-ctc-cxx-api.cc#L24-L33)

**Section sources**
- [streaming-zipformer-cxx-api.cc](file://cxx-api-examples/streaming-zipformer-cxx-api.cc#L24-L44)
- [streaming-zipformer-rtf-cxx-api.cc](file://cxx-api-examples/streaming-zipformer-rtf-cxx-api.cc#L52-L73)

## 音频流处理流程

### 音频流处理完整流程
流式语音识别的完整流程包括音频流建立、数据分块、实时推理和结果流式输出。

```mermaid
flowchart TD
A[开始] --> B[创建OnlineRecognizer]
B --> C[创建OnlineStream]
C --> D[分块接受音频数据]
D --> E{是否完成输入?}
E --> |否| D
E --> |是| F[标记输入完成]
F --> G{是否准备就绪?}
G --> |是| H[执行解码]
H --> G
G --> |否| I[获取最终结果]
I --> J[结束]
```

**Diagram sources**
- [streaming-zipformer-cxx-api.cc](file://cxx-api-examples/streaming-zipformer-cxx-api.cc#L66-L75)
- [streaming-t-one-ctc-cxx-api.cc](file://cxx-api-examples/streaming-t-one-ctc-cxx-api.cc#L55-L71)

**Section sources**
- [streaming-zipformer-cxx-api.cc](file://cxx-api-examples/streaming-zipformer-cxx-api.cc#L66-L75)
- [streaming-t-one-ctc-cxx-api.cc](file://cxx-api-examples/streaming-t-one-ctc-cxx-api.cc#L55-L71)

## 基于Zipformer的流式识别

### Zipformer流式识别实现
Zipformer是一种先进的流式语音识别模型架构，支持CTC和Transducer两种模式。

```mermaid
sequenceDiagram
participant 应用程序
participant OnlineRecognizer
participant OnlineStream
participant 模型推理
应用程序->>OnlineRecognizer : 创建配置
应用程序->>OnlineRecognizer : Create()
OnlineRecognizer-->>应用程序 : OnlineRecognizer实例
应用程序->>OnlineRecognizer : CreateStream()
OnlineRecognizer-->>应用程序 : OnlineStream实例
应用程序->>OnlineStream : AcceptWaveform()
OnlineStream->>模型推理 : 处理音频块
应用程序->>OnlineStream : InputFinished()
应用程序->>OnlineRecognizer : IsReady()
OnlineRecognizer-->>应用程序 : true
应用程序->>OnlineRecognizer : Decode()
模型推理->>OnlineStream : 更新识别状态
应用程序->>OnlineRecognizer : GetResult()
OnlineRecognizer-->>应用程序 : 识别文本
```

**Diagram sources**
- [streaming-zipformer-cxx-api.cc](file://cxx-api-examples/streaming-zipformer-cxx-api.cc#L24-L85)
- [streaming-zipformer-rtf-cxx-api.cc](file://cxx-api-examples/streaming-zipformer-rtf-cxx-api.cc#L52-L121)

**Section sources**
- [streaming-zipformer-cxx-api.cc](file://cxx-api-examples/streaming-zipformer-cxx-api.cc#L24-L85)
- [streaming-zipformer-rtf-cxx-api.cc](file://cxx-api-examples/streaming-zipformer-rtf-cxx-api.cc#L52-L121)

## 基于T-One CTC的流式识别

### T-One CTC流式识别实现
T-One CTC是一种基于CTC的流式语音识别模型，具有高效的推理性能。

```mermaid
flowchart TD
A[开始] --> B[配置T-One模型路径]
B --> C[设置token文件]
C --> D[创建OnlineRecognizer]
D --> E[创建OnlineStream]
E --> F[接受音频数据]
F --> G[添加前后padding]
G --> H[标记输入完成]
H --> I[循环解码]
I --> J[获取最终结果]
J --> K[结束]
```

**Diagram sources**
- [streaming-t-one-ctc-cxx-api.cc](file://cxx-api-examples/streaming-t-one-ctc-cxx-api.cc#L24-L90)

**Section sources**
- [streaming-t-one-ctc-cxx-api.cc](file://cxx-api-examples/streaming-t-one-ctc-cxx-api.cc#L24-L90)

## 基于Wenet CTC的流式识别

### Wenet CTC流式识别实现
Wenet CTC模型结合了语音活动检测(VAD)技术，实现更智能的流式识别。

```mermaid
sequenceDiagram
participant 应用程序
participant VAD
participant 识别器
participant 麦克风
麦克风->>应用程序 : 音频数据
应用程序->>VAD : 接受音频块
VAD->>应用程序 : 语音检测结果
应用程序->>识别器 : 创建流
识别器->>应用程序 : 流实例
应用程序->>识别器 : 解码
识别器->>应用程序 : 识别结果
应用程序->>显示 : 更新文本
```

**Diagram sources**
- [wenet-ctc-simulate-streaming-microphone-cxx-api.cc](file://cxx-api-examples/wenet-ctc-simulate-streaming-microphone-cxx-api.cc#L59-L77)
- [wenet-ctc-simulate-streaming-microphone-cxx-api.cc](file://cxx-api-examples/wenet-ctc-simulate-streaming-microphone-cxx-api.cc#L106-L107)

**Section sources**
- [wenet-ctc-simulate-streaming-microphone-cxx-api.cc](file://cxx-api-examples/wenet-ctc-simulate-streaming-microphone-cxx-api.cc#L59-L77)
- [wenet-ctc-simulate-streaming-microphone-cxx-api.cc](file://cxx-api-examples/wenet-ctc-simulate-streaming-microphone-cxx-api.cc#L106-L107)

## 基于SenseVoice的流式识别

### SenseVoice流式识别实现
SenseVoice是一种多语言流式语音识别模型，支持中文、英文、日文等多种语言。

```mermaid
classDiagram
class VadModelConfig {
+string silero_vad.model
+float silero_vad.threshold
+float silero_vad.min_silence_duration
+float silero_vad.min_speech_duration
+float silero_vad.max_speech_duration
+int32_t sample_rate
+bool debug
}
class OfflineRecognizerConfig {
+ModelConfig model_config
+VadModelConfig vad_config
}
class ModelConfig {
+string sense_voice.model
+bool sense_voice.use_itn
+string sense_voice.language
+string tokens
+int32_t num_threads
+bool debug
}
OfflineRecognizerConfig --> ModelConfig : "包含"
OfflineRecognizerConfig --> VadModelConfig : "包含"
```

**Diagram sources**
- [sense-voice-simulate-streaming-alsa-cxx-api.cc](file://cxx-api-examples/sense-voice-simulate-streaming-alsa-cxx-api.cc#L56-L85)
- [sense-voice-simulate-streaming-microphone-cxx-api.cc](file://cxx-api-examples/sense-voice-simulate-streaming-microphone-cxx-api.cc#L60-L89)

**Section sources**
- [sense-voice-simulate-streaming-alsa-cxx-api.cc](file://cxx-api-examples/sense-voice-simulate-streaming-alsa-cxx-api.cc#L56-L85)
- [sense-voice-simulate-streaming-microphone-cxx-api.cc](file://cxx-api-examples/sense-voice-simulate-streaming-microphone-cxx-api.cc#L60-L89)

## 使用ALSA和麦克风的模拟流式处理

### ALSA音频输入处理
ALSA(Advanced Linux Sound Architecture)是Linux系统下的音频处理框架，用于从麦克风获取实时音频数据。

```mermaid
flowchart TD
A[开始] --> B[初始化ALSA]
B --> C[创建音频回调]
C --> D[启动录音线程]
D --> E[音频数据入队]
E --> F[VAD处理]
F --> G{检测到语音?}
G --> |是| H[开始识别]
H --> I[更新显示]
G --> |否| E
I --> J{语音结束?}
J --> |是| K[完成句子]
K --> E
J --> |否| I
```

**Diagram sources**
- [sense-voice-simulate-streaming-alsa-cxx-api.cc](file://cxx-api-examples/sense-voice-simulate-streaming-alsa-cxx-api.cc#L45-L54)
- [zipformer-ctc-simulate-streaming-alsa-cxx-api.cc](file://cxx-api-examples/zipformer-ctc-simulate-streaming-alsa-cxx-api.cc#L45-L54)

**Section sources**
- [sense-voice-simulate-streaming-alsa-cxx-api.cc](file://cxx-api-examples/sense-voice-simulate-streaming-alsa-cxx-api.cc#L45-L54)
- [zipformer-ctc-simulate-streaming-alsa-cxx-api.cc](file://cxx-api-examples/zipformer-ctc-simulate-streaming-alsa-cxx-api.cc#L45-L54)

### 麦克风音频输入处理
使用PortAudio库从麦克风获取音频数据，适用于跨平台应用。

```mermaid
sequenceDiagram
participant 应用程序
participant PortAudio
participant 麦克风
participant 数据队列
麦克风->>PortAudio : 音频数据
PortAudio->>应用程序 : 回调函数
应用程序->>数据队列 : 存储音频块
数据队列->>VAD : 提供音频数据
VAD->>识别器 : 触发识别
识别器->>显示 : 输出文本
```

**Diagram sources**
- [wenet-ctc-simulate-streaming-microphone-cxx-api.cc](file://cxx-api-examples/wenet-ctc-simulate-streaming-microphone-cxx-api.cc#L44-L57)
- [zipformer-transducer-simulate-streaming-microphone-cxx-api.cc](file://cxx-api-examples/zipformer-transducer-simulate-streaming-microphone-cxx-api.cc#L44-L57)

**Section sources**
- [wenet-ctc-simulate-streaming-microphone-cxx-api.cc](file://cxx-api-examples/wenet-ctc-simulate-streaming-microphone-cxx-api.cc#L44-L57)
- [zipformer-transducer-simulate-streaming-microphone-cxx-api.cc](file://cxx-api-examples/zipformer-transducer-simulate-streaming-microphone-cxx-api.cc#L44-L57)

## 实时因子(RTF)计算与监控

### RTF计算方法
实时因子(Real Time Factor)是衡量语音识别系统性能的重要指标，表示处理时间与音频时长的比率。

```mermaid
flowchart TD
A[开始计时] --> B[加载模型]
B --> C[处理音频]
C --> D[结束计时]
D --> E[计算耗时]
E --> F[计算音频时长]
F --> G[计算RTF = 耗时/时长]
G --> H[输出性能指标]
```

**Diagram sources**
- [streaming-zipformer-cxx-api.cc](file://cxx-api-examples/streaming-zipformer-cxx-api.cc#L64-L90)
- [streaming-zipformer-rtf-cxx-api.cc](file://cxx-api-examples/streaming-zipformer-rtf-cxx-api.cc#L96-L132)

**Section sources**
- [streaming-zipformer-cxx-api.cc](file://cxx-api-examples/streaming-zipformer-cxx-api.cc#L64-L90)
- [streaming-zipformer-rtf-cxx-api.cc](file://cxx-api-examples/streaming-zipformer-rtf-cxx-api.cc#L96-L132)

## 上下文管理与状态同步

### 流式识别状态管理
流式语音识别需要有效管理识别状态，确保上下文的连续性和一致性。

```mermaid
stateDiagram-v2
[*] --> 空闲
空闲 --> 音频缓冲 : 接收音频
音频缓冲 --> VAD检测 : 定期检查
VAD检测 --> 语音活动 : 检测到语音
VAD检测 --> 音频缓冲 : 无语音
语音活动 --> 识别进行 : 开始识别
识别进行 --> 结果输出 : 获取结果
结果输出 --> 句子完成 : 语音结束
句子完成 --> 空闲 : 重置状态
```

**Diagram sources**
- [wenet-ctc-simulate-streaming-microphone-cxx-api.cc](file://cxx-api-examples/wenet-ctc-simulate-streaming-microphone-cxx-api.cc#L184-L237)
- [sense-voice-simulate-streaming-microphone-cxx-api.cc](file://cxx-api-examples/sense-voice-simulate-streaming-microphone-cxx-api.cc#L188-L239)

**Section sources**
- [wenet-ctc-simulate-streaming-microphone-cxx-api.cc](file://cxx-api-examples/wenet-ctc-simulate-streaming-microphone-cxx-api.cc#L184-L237)
- [sense-voice-simulate-streaming-microphone-cxx-api.cc](file://cxx-api-examples/sense-voice-simulate-streaming-microphone-cxx-api.cc#L188-L239)