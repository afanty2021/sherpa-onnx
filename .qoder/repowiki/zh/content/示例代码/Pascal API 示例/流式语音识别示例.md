# 流式语音识别示例

<cite>
**本文档引用的文件**   
- [nemo_transducer.pas](file://pascal-api-examples/streaming-asr/nemo_transducer.pas)
- [paraformer.pas](file://pascal-api-examples/streaming-asr/paraformer.pas)
- [t_one_ctc.pas](file://pascal-api-examples/streaming-asr/t_one_ctc.pas)
- [zipformer_ctc.pas](file://pascal-api-examples/streaming-asr/zipformer_ctc.pas)
- [zipformer_ctc_hlg.pas](file://pascal-api-examples/streaming-asr/zipformer_ctc_hlg.pas)
- [zipformer_transducer.pas](file://pascal-api-examples/streaming-asr/zipformer_transducer.pas)
- [sherpa_onnx.pas](file://sherpa-onnx/pascal-api/sherpa_onnx.pas)
</cite>

## 目录
1. [引言](#引言)
2. [流式ASR模型实现机制](#流式asr模型实现机制)
3. [流式识别器创建与音频处理](#流式识别器创建与音频处理)
4. [流式与非流式识别对比](#流式与非流式识别对比)
5. [延迟、实时性与资源消耗](#延迟实时性与资源消耗)
6. [性能优化建议](#性能优化建议)

## 引言

本示例文档详细介绍了如何使用sherpa-onnx的Pascal API实现流式语音识别。文档涵盖了nemo_transducer、paraformer、t_one_ctc、zipformer系列等流式ASR模型的实现机制，包括如何创建流式识别器、分块送入音频数据、实时获取识别结果。同时，文档对比了流式与非流式识别在Pascal实现上的差异，并提供了处理延迟、实时性和资源消耗问题的性能优化建议。

## 流式ASR模型实现机制

sherpa-onnx的Pascal API为多种流式ASR模型提供了统一的接口，包括NeMo Transducer、Paraformer、T-one CTC和Zipformer系列模型。这些模型在Pascal中的实现机制基于相同的流式识别框架，通过`TSherpaOnnxOnlineRecognizer`类和`TSherpaOnnxOnlineStream`类进行管理。

### NeMo Transducer模型

NeMo Transducer模型是一种基于RNN-T（Recurrent Neural Network Transducer）架构的流式语音识别模型。在Pascal中，通过配置`TSherpaOnnxOnlineRecognizerConfig`对象的`ModelConfig.Transducer`字段来指定模型文件路径。该模型由编码器（encoder）、解码器（decoder）和连接器（joiner）三个ONNX模型文件组成，能够实现低延迟的流式识别。

**模型配置示例：**
```pascal
Config.ModelConfig.Transducer.Encoder := './sherpa-onnx-nemo-streaming-fast-conformer-transducer-en-80ms/encoder.onnx';
Config.ModelConfig.Transducer.Decoder := './sherpa-onnx-nemo-streaming-fast-conformer-transducer-en-80ms/decoder.onnx';
Config.ModelConfig.Transducer.Joiner := './sherpa-onnx-nemo-streaming-fast-conformer-transducer-en-80ms/joiner.onnx';
```

### Paraformer模型

Paraformer是一种高效的流式语音识别模型，特别适用于双语（中英文）识别场景。在Pascal中，通过配置`ModelConfig.Paraformer`字段来指定Paraformer模型。该模型同样由编码器和解码器两个ONNX文件组成，支持INT8量化以提高推理速度。

**模型配置示例：**
```pascal
Config.ModelConfig.Paraformer.Encoder := './sherpa-onnx-streaming-paraformer-bilingual-zh-en/encoder.int8.onnx';
Config.ModelConfig.Paraformer.Decoder := './sherpa-onnx-streaming-paraformer-bilingual-zh-en/decoder.int8.onnx';
```

### T-one CTC模型

T-one CTC模型是一种基于CTC（Connectionist Temporal Classification）架构的流式语音识别模型，特别适用于俄语等语言。该模型在Pascal中通过`ModelConfig.ToneCtc`字段进行配置，只需要一个主模型文件和一个词元文件。

**模型配置示例：**
```pascal
Config.ModelConfig.ToneCtc.Model := './sherpa-onnx-streaming-t-one-russian-2025-09-08/model.onnx';
```

### Zipformer系列模型

Zipformer系列模型包括Zipformer CTC和Zipformer Transducer两种变体，提供了高性能的流式语音识别能力。Zipformer CTC模型通过`ModelConfig.Zipformer2Ctc`字段配置，而Zipformer Transducer模型则通过`ModelConfig.Transducer`字段配置。

**Zipformer CTC模型配置示例：**
```pascal
Config.ModelConfig.Zipformer2Ctc.Model := './sherpa-onnx-streaming-zipformer-ctc-small-2024-03-18/ctc-epoch-30-avg-3-chunk-16-left-128.int8.onnx';
```

**Zipformer Transducer模型配置示例：**
```pascal
Config.ModelConfig.Transducer.Encoder := './sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20/encoder-epoch-99-avg-1.int8.onnx';
Config.ModelConfig.Transducer.Decoder := './sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20/decoder-epoch-99-avg-1.onnx';
Config.ModelConfig.Transducer.Joiner := './sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20/joiner-epoch-99-avg-1.int8.onnx';
```

**Section sources**
- [nemo_transducer.pas](file://pascal-api-examples/streaming-asr/nemo_transducer.pas)
- [paraformer.pas](file://pascal-api-examples/streaming-asr/paraformer.pas)
- [t_one_ctc.pas](file://pascal-api-examples/streaming-asr/t_one_ctc.pas)
- [zipformer_ctc.pas](file://pascal-api-examples/streaming-asr/zipformer_ctc.pas)
- [zipformer_transducer.pas](file://pascal-api-examples/streaming-asr/zipformer_transducer.pas)

## 流式识别器创建与音频处理

### 流式识别器创建

在Pascal中创建流式识别器需要以下步骤：

1. **初始化配置**：创建`TSherpaOnnxOnlineRecognizerConfig`对象并初始化
2. **配置模型参数**：根据所选模型类型设置相应的模型文件路径
3. **创建识别器**：使用配置对象创建`TSherpaOnnxOnlineRecognizer`实例

```pascal
// 初始化配置
Initialize(Config);

// 配置模型参数（以NeMo Transducer为例）
Config.ModelConfig.Transducer.Encoder := './path/to/encoder.onnx';
Config.ModelConfig.Transducer.Decoder := './path/to/decoder.onnx';
Config.ModelConfig.Transducer.Joiner := './path/to/joiner.onnx';
Config.ModelConfig.Tokens := './path/to/tokens.txt';

// 创建识别器
Recognizer := TSherpaOnnxOnlineRecognizer.Create(Config);
```

### 音频数据分块送入

流式语音识别的核心是能够分块处理音频数据。在Pascal中，通过`TSherpaOnnxOnlineStream`类的`AcceptWaveform`方法实现音频数据的分块送入。

```pascal
// 创建流式处理流
Stream := Recognizer.CreateStream();

// 送入音频数据
Stream.AcceptWaveform(Wave.Samples, Wave.SampleRate);
```

对于实时音频流，可以循环调用`AcceptWaveform`方法，每次送入一小块音频数据（如0.1秒或0.2秒的音频片段）。

### 实时获取识别结果

流式识别的关键优势是能够实时获取部分识别结果。在Pascal中，通过以下流程实现：

1. **检查就绪状态**：使用`IsReady`方法检查流是否准备好解码
2. **执行解码**：调用`Decode`方法进行解码
3. **获取结果**：通过`GetResult`方法获取当前识别结果

```pascal
// 送入音频数据后，持续解码直到流不再就绪
while Recognizer.IsReady(Stream) do
  Recognizer.Decode(Stream);

// 获取最终识别结果
RecognitionResult := Recognizer.GetResult(Stream);
```

对于实时应用，可以在音频输入的同时周期性地检查并获取部分识别结果，实现真正的实时语音识别。

**Section sources**
- [nemo_transducer.pas](file://pascal-api-examples/streaming-asr/nemo_transducer.pas)
- [sherpa_onnx.pas](file://sherpa-onnx/pascal-api/sherpa_onnx.pas)

## 流式与非流式识别对比

### 状态管理差异

流式识别和非流式识别在状态管理上有显著差异：

**流式识别状态管理：**
- 使用`TSherpaOnnxOnlineStream`对象维护识别状态
- 状态在识别过程中持续更新
- 支持中途获取部分识别结果
- 可以处理无限长度的音频流

**非流式识别状态管理：**
- 使用`TSherpaOnnxOfflineStream`对象
- 需要一次性提供完整的音频数据
- 识别完成后才能获取结果
- 适用于已知长度的音频文件识别

### 回调函数使用

流式识别支持更灵活的回调机制，允许在识别过程中实时获取结果。在Pascal中，虽然示例代码没有直接展示回调函数，但流式API的设计支持在`Decode`循环中插入回调逻辑。

```pascal
// 流式识别中的回调模式
while Recognizer.IsReady(Stream) do
begin
  Recognizer.Decode(Stream);
  
  // 在此处插入回调逻辑，实时处理部分识别结果
  RecognitionResult := Recognizer.GetResult(Stream);
  if RecognitionResult.Text <> '' then
    // 调用回调函数处理部分结果
    OnPartialResult(RecognitionResult.Text);
end;
```

相比之下，非流式识别通常在识别完成后一次性返回结果，回调机制相对简单。

### 性能特征对比

| 特性 | 流式识别 | 非流式识别 |
|------|----------|----------|
| 延迟 | 低（可实时输出） | 高（需等待完整音频） |
| 内存使用 | 中等（维护状态） | 低（一次性处理） |
| 适用场景 | 实时语音交互 | 批量音频处理 |
| 模型支持 | 专门的流式模型 | 通用ASR模型 |

**Section sources**
- [nemo_transducer.pas](file://pascal-api-examples/streaming-asr/nemo_transducer.pas)
- [sherpa_onnx.pas](file://sherpa-onnx/pascal-api/sherpa_onnx.pas)

## 延迟、实时性与资源消耗

### 延迟处理

流式语音识别的延迟主要由以下几个因素决定：

1. **模型架构**：不同模型的固有延迟不同，如NeMo Transducer通常有80ms的延迟
2. **音频块大小**：送入的音频块越大，处理延迟越高
3. **计算资源**：CPU/GPU性能直接影响处理速度

在Pascal实现中，可以通过调整音频块大小来平衡延迟和性能：

```pascal
// 使用较小的音频块（如0.1秒）降低延迟
SetLength(AudioChunk, Round(SampleRate * 0.1));
```

### 实时性保障

为了确保实时性，需要保证处理速度不落后于音频输入速度。关键指标是实时因子（RTF, Real Time Factor），即处理时间与音频时长的比值。RTF小于1表示系统能够实时处理。

```pascal
// 计算实时因子
Elapsed := MilliSecondsBetween(Stop, Start) / 1000; // 处理耗时（秒）
Duration := Length(Wave.Samples) / Wave.SampleRate; // 音频时长（秒）
RealTimeFactor := Elapsed / Duration; // RTF
```

### 资源消耗优化

流式识别的资源消耗主要体现在内存和CPU使用上。优化策略包括：

1. **模型量化**：使用INT8量化的模型文件（如`.int8.onnx`）减少内存占用和计算量
2. **线程控制**：通过`NumThreads`参数控制并行线程数，平衡性能和资源消耗
3. **采样率匹配**：确保输入音频采样率与模型期望的采样率一致，避免不必要的重采样

```pascal
// 优化资源配置
Config.ModelConfig.NumThreads := 2; // 根据CPU核心数调整
Config.ModelConfig.Provider := 'cpu'; // 选择合适的计算后端
```

**Section sources**
- [nemo_transducer.pas](file://pascal-api-examples/streaming-asr/nemo_transducer.pas)
- [sherpa_onnx.pas](file://sherpa-onnx/pascal-api/sherpa_onnx.pas)

## 性能优化建议

### 模型选择优化

根据应用场景选择合适的流式ASR模型：

- **高精度需求**：选择Zipformer系列模型
- **低延迟需求**：选择NeMo Transducer或Paraformer模型
- **多语言支持**：选择支持多语言的模型如Zipformer Transducer双语模型
- **资源受限环境**：选择INT8量化的模型以减少内存占用

### 音频处理优化

1. **预填充和后填充**：在音频开始前添加少量静音（左填充）和结束后添加静音（右填充）可以提高识别准确率
```pascal
// 添加0.3秒左填充和0.6秒右填充
SetLength(LeftPaddings, Round(Wave.SampleRate * 0.3));
SetLength(TailPaddings, Round(Wave.SampleRate * 0.6));
Stream.AcceptWaveform(LeftPaddings, Wave.SampleRate);
Stream.AcceptWaveform(Wave.Samples, Wave.SampleRate);
Stream.AcceptWaveform(TailPaddings, Wave.SampleRate);
```

2. **采样率匹配**：确保音频采样率与模型期望的采样率一致，避免不必要的重采样开销

### 系统配置优化

1. **计算后端选择**：根据硬件环境选择合适的计算后端
```pascal
Config.ModelConfig.Provider := 'cpu'; // CPU模式
// Config.ModelConfig.Provider := 'cuda'; // GPU模式（如果支持）
```

2. **线程数配置**：根据CPU核心数合理设置线程数
```pascal
Config.ModelConfig.NumThreads := 4; // 四核CPU
```

3. **内存管理**：及时释放不再使用的资源，避免内存泄漏
```pascal
// 识别完成后释放资源
FreeAndNil(Stream);
FreeAndNil(Recognizer);
```

### 实时应用优化

对于实时语音识别应用，建议采用以下优化策略：

1. **小块音频输入**：每次送入较小的音频块（如0.1-0.2秒），以降低延迟
2. **异步处理**：将音频采集和识别处理分离到不同线程，确保实时性
3. **结果缓存**：缓存部分识别结果，避免重复计算
4. **端点检测**：使用内置的端点检测功能自动识别语音结束

通过综合运用这些优化策略，可以显著提升流式语音识别系统的性能和用户体验。

**Section sources**
- [nemo_transducer.pas](file://pascal-api-examples/streaming-asr/nemo_transducer.pas)
- [sherpa_onnx.pas](file://sherpa-onnx/pascal-api/sherpa_onnx.pas)