[æ ¹ç›®å½•](../CLAUDE.md) > **ios**

# iOS é›†æˆ

> æ›´æ–°æ—¶é—´ï¼š2025-12-10 07:48:28

## æ¨¡å—èŒè´£

Sherpa-ONNX çš„ iOS é›†æˆæ¨¡å—æä¾›äº†å®Œæ•´çš„ iOS å¹³å°è¯­éŸ³å¤„ç†è§£å†³æ–¹æ¡ˆã€‚å®ƒé€šè¿‡ Swift/Objective-C ç»‘å®šå°† C++ æ ¸å¿ƒåŠŸèƒ½å°è£…ä¸º iOS åŸç”Ÿ APIï¼Œæ”¯æŒä»¥ä¸‹åŠŸèƒ½ï¼š

- **å®æ—¶è¯­éŸ³è¯†åˆ«**ï¼šæµå¼ ASRï¼Œæ”¯æŒéº¦å…‹é£è¾“å…¥
- **è¯­éŸ³åˆæˆ**ï¼šTTS åŠŸèƒ½ï¼Œæ”¯æŒå¤šç§å£°éŸ³
- **è¯­è¨€è¯†åˆ«**ï¼šè¯†åˆ«è¯­éŸ³è¯­è¨€
- **å­—å¹•ç”Ÿæˆ**ï¼šéŸ³é¢‘/è§†é¢‘å­—å¹•å®æ—¶ç”Ÿæˆ
- **ä¸¤éè¯†åˆ«**ï¼šå¿«é€Ÿåˆè¯†åˆ« + ç²¾ç¡®è°ƒæ•´

## é¡¹ç›®ç»“æ„

### iOS ç¤ºä¾‹é¡¹ç›®

```
ios-swiftui/                    # SwiftUI ç¤ºä¾‹åº”ç”¨
â”œâ”€â”€ SherpaOnnx/                # åŸºç¡€è¯­éŸ³è¯†åˆ«åº”ç”¨
â”œâ”€â”€ SherpaOnnx2Pass/           # ä¸¤éè¯†åˆ«åº”ç”¨
â”œâ”€â”€ SherpaOnnxTts/             # TTS è¯­éŸ³åˆæˆåº”ç”¨
â”œâ”€â”€ SherpaOnnxLangID/          # è¯­è¨€è¯†åˆ«åº”ç”¨
â””â”€â”€ SherpaOnnxSubtitle/        # å­—å¹•ç”Ÿæˆåº”ç”¨

ios-swift/                     # UIKit ç¤ºä¾‹åº”ç”¨
â””â”€â”€ SherpaOnnx/                # UIKit ç‰ˆæœ¬ç¤ºä¾‹
```

### æ ¸å¿ƒç»„ä»¶

```
æ¯ä¸ªç¤ºä¾‹é¡¹ç›®åŒ…å«ï¼š
â”œâ”€â”€ Model.swift                # æ¨¡å‹é…ç½®
â”œâ”€â”€ ViewModel.swift            # ä¸šåŠ¡é€»è¾‘
â”œâ”€â”€ ContentView.swift          # SwiftUI ç•Œé¢
â”œâ”€â”€ ViewController.swift       # UIKit ç•Œé¢
â””â”€â”€ Extension.swift            # æ‰©å±•å·¥å…·
```

## å…¥å£ä¸å¯åŠ¨

### 1. ç¯å¢ƒè¦æ±‚

- **Xcode**ï¼š14.0+
- **iOS éƒ¨ç½²ç›®æ ‡**ï¼š13.0+
- **Swift**ï¼š5.5+
- **è®¾å¤‡**ï¼šæ”¯æŒ iOS çš„ iPhone/iPad

### 2. å¿«é€Ÿé›†æˆ

#### æ­¥éª¤ 1ï¼šæ·»åŠ  Sherpa-ONNX ä¾èµ–

```swift
// ä½¿ç”¨ Swift Package Manager
// File > Add Packages...
// è¾“å…¥ï¼šhttps://github.com/k2-fsa/sherpa-onnx.git
```

#### æ­¥éª¤ 2ï¼šé…ç½®æ¨¡å‹æ–‡ä»¶

1. ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹ï¼š
```bash
# ä¸­æ–‡+è‹±æ–‡åŒè¯­æ¨¡å‹
wget https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-paraformer-bilingual-zh-en-2023-02-20.tar.bz2
tar xf sherpa-onnx-streaming-paraformer-bilingual-zh-en-2023-02-20.tar.bz2
```

2. æ·»åŠ åˆ° Xcode é¡¹ç›®ï¼š
```
Build Phases > Copy Bundle Resources > æ·»åŠ æ¨¡å‹æ–‡ä»¶
```

#### æ­¥éª¤ 3ï¼šåŸºç¡€ä»£ç ç¤ºä¾‹

```swift
import SwiftUI
import SherpaOnnx

struct ContentView: View {
    @StateObject private var viewModel = SherpaOnnxViewModel()

    var body: some View {
        VStack(spacing: 20) {
            Text("å®æ—¶è¯­éŸ³è¯†åˆ«")
                .font(.largeTitle)

            Text(viewModel.subtitles)
                .padding()
                .background(Color.gray.opacity(0.1))
                .cornerRadius(10)

            Button(action: {
                if viewModel.status == .stop {
                    viewModel.startRecording()
                } else {
                    viewModel.stopRecording()
                }
            }) {
                Text(viewModel.status == .stop ? "å¼€å§‹" : "åœæ­¢")
                    .padding()
                    .background(viewModel.status == .stop ? Color.green : Color.red)
                    .foregroundColor(.white)
                    .cornerRadius(10)
            }
        }
        .padding()
    }
}
```

## å¯¹å¤–æ¥å£

### 1. è¯­éŸ³è¯†åˆ«æ¥å£

#### é…ç½®æ¨¡å‹
```swift
// åœ¨ Model.swift ä¸­é…ç½®
func getBilingualStreamingZhEnParaformer() -> SherpaOnnxOnlineModelConfig {
    let encoder = getResource("encoder.int8", "onnx")
    let decoder = getResource("decoder.int8", "onnx")
    let tokens = getResource("tokens", "txt")

    return sherpaOnnxOnlineModelConfig(
        tokens: tokens,
        paraformer: sherpaOnnxOnlineParaformerModelConfig(
            encoder: encoder,
            decoder: decoder
        ),
        numThreads: 1,
        modelType: "paraformer"
    )
}
```

#### è¯†åˆ«å™¨åˆå§‹åŒ–
```swift
class SherpaOnnxViewModel: ObservableObject {
    private var recognizer: SherpaOnnxRecognizer!

    private func initRecognizer() {
        let modelConfig = getBilingualStreamingZhEnParaformer()

        let featConfig = sherpaOnnxFeatureConfig(
            sampleRate: 16000,
            featureDim: 80
        )

        var config = sherpaOnnxOnlineRecognizerConfig(
            featConfig: featConfig,
            modelConfig: modelConfig,
            enableEndpoint: true,
            rule1MinTrailingSilence: 2.4,
            rule2MinTrailingSilence: 0.8,
            rule3MinUtteranceLength: 30,
            decodingMethod: "greedy_search",
            maxActivePaths: 4
        )

        recognizer = SherpaOnnxRecognizer(config: &config)
    }
}
```

#### å®æ—¶è¯†åˆ«
```swift
private func initRecorder() {
    audioEngine = AVAudioEngine()

    // è·å–è¾“å…¥èŠ‚ç‚¹
    let inputNode = audioEngine!.inputNode
    let inputFormat = inputNode.outputFormat(forBus: 0)

    // è®¾ç½®éŸ³é¢‘å¤„ç†æ ¼å¼
    let recordingFormat = AVAudioFormat(
        commonFormat: .pcmFormatFloat32,
        sampleRate: 16000,
        channels: 1,
        interleaved: false
    )!

    // å®‰è£…éŸ³é¢‘å¤„ç†å›è°ƒ
    inputNode.installTap(
        onBus: 0,
        bufferSize: 4096,
        format: recordingFormat
    ) { [weak self] buffer, _ in
            guard let self = self,
                  let channelData = buffer.floatChannelData?[0] else {
                return
            }

            // å¤„ç†éŸ³é¢‘æ•°æ®
            let array = Array(UnsafeBufferPointer(
                start: channelData,
                count: Int(buffer.frameLength)
            ))

            // è¯†åˆ«
            self.recognizer.acceptWaveform(samples: array)

            // è·å–ç»“æœ
            if self.recognizer.isReady() {
                self.recognizer.decode()
                let result = self.recognizer.getResult()
                DispatchQueue.main.async {
                    self.updateResult(result.text)
                }
            }
        }
}
```

### 2. è¯­éŸ³åˆæˆæ¥å£

```swift
class TtsViewModel: ObservableObject {
    private var tts: SherpaOnnxOfflineTts!

    private func initTts() {
        let modelConfig = SherpaOnnxOfflineTtsModelConfig(
            vits: SherpaOnnxOfflineTtsVitsModelConfig(
                model: getResource("model", "onnx"),
                lexicon: getResource("lexicon", "txt"),
                tokens: getResource("tokens", "txt")
            ),
            numThreads: 1,
            debug: true,
            provider: "cpu"
        )

        let config = SherpaOnnxOfflineTtsConfig(
            model: modelConfig,
            ruleFsts: "",
            ruleFars: "",
            maxNumSentences: 2
        )

        tts = SherpaOnnxOfflineTts(config: config)
    }

    func generateSpeech(text: String) {
        let audio = tts.generate(text: text, speakerId: 0, speed: 1.0)

        // æ’­æ”¾éŸ³é¢‘
        let avAudioBuffer = AVAudioPCMBuffer(
            pcmFormat: AVAudioFormat(
                commonFormat: .pcmFormatFloat32,
                sampleRate: Double(audio.sampleRate),
                channels: 1,
                interleaved: false
            )!,
            frameCapacity: AVAudioFrameCount(audio.samples.count)
        )!

        avAudioBuffer.floatChannelData![0].assign(
            from: audio.samples,
            count: audio.samples.count
        )

        let playerNode = AVAudioPlayerNode()
        audioEngine.attach(playerNode)
        audioEngine.connect(playerNode, to: audioEngine.mainMixerNode, format: nil)

        playerNode.scheduleBuffer(avAudioBuffer)
        audioEngine.start()
        playerNode.play()
    }
}
```

### 3. å­—å¹•ç”Ÿæˆæ¥å£

```swift
class SubtitleViewModel: ObservableObject {
    @Published var subtitles: [SpeechSegment] = []

    func generateSubtitles(from url: URL) async {
        // åŠ è½½éŸ³é¢‘æ–‡ä»¶
        let asset = AVAsset(url: url)
        guard let track = asset.tracks(withMediaType: .audio).first else { return }

        // åˆ›å»ºè¯†åˆ«å™¨
        let recognizer = SherpaOnnxRecognizer(config: &config)

        // è¯»å–éŸ³é¢‘æ•°æ®
        let reader = try! AVAssetReader(asset)
        let output = AVAssetReaderTrackOutput(
            track: track,
            outputSettings: [
                AVFormatIDKey: kAudioFormatLinearPCM,
                AVLinearPCMIsFloatKey: true,
                AVLinearPCMIsBigEndianKey: false,
                AVLinearPCMBitDepthKey: 32,
                AVLinearPCMIsNonInterleaved: true
            ]
        )

        reader.add(output)
        reader.startReading()

        // åˆ†æ®µå¤„ç†
        var segmentCount = 0
        let segmentDuration: Double = 10.0  // 10ç§’ä¸€æ®µ

        while reader.status == .reading {
            guard let buffer = output.copyNextSampleBuffer() else { continue }

            // å¤„ç†éŸ³é¢‘ç‰‡æ®µ
            let audioData = extractAudioData(from: buffer)
            recognizer.acceptWaveform(samples: audioData)

            if recognizer.isReady() {
                recognizer.decode()
                let result = recognizer.getResult()

                if !result.text.isEmpty {
                    let startTime = Double(segmentCount) * segmentDuration
                    let segment = SpeechSegment(
                        startTime: startTime,
                        endTime: startTime + segmentDuration,
                        text: result.text
                    )

                    await MainActor.run {
                        subtitles.append(segment)
                    }
                }
            }

            segmentCount += 1
        }
    }
}
```

## å…³é”®ä¾èµ–ä¸é…ç½®

### ç³»ç»Ÿæ¡†æ¶
- **AVFoundation**ï¼šéŸ³é¢‘é‡‡é›†å’Œæ’­æ”¾
- **Combine**ï¼šå“åº”å¼ç¼–ç¨‹
- **SwiftUI**ï¼šå£°æ˜å¼ UI
- **Foundation**ï¼šåŸºç¡€åŠŸèƒ½

### æƒé™é…ç½®

åœ¨ `Info.plist` ä¸­æ·»åŠ ï¼š
```xml
<key>NSMicrophoneUsageDescription</key>
<string>æ­¤åº”ç”¨éœ€è¦è®¿é—®éº¦å…‹é£è¿›è¡Œè¯­éŸ³è¯†åˆ«</string>

<key>NSDocumentsFolderUsageDescription</key>
<string>æ­¤åº”ç”¨éœ€è¦è®¿é—®æ–‡æ¡£æ–‡ä»¶å¤¹åŠ è½½éŸ³é¢‘æ–‡ä»¶</string>
```

### æ„å»ºè®¾ç½®

```swift
// Package.swift
// swift-tools-version:5.7
import PackageDescription

let package = Package(
    name: "SherpaOnnxExample",
    platforms: [
        .iOS(.v13)
    ],
    products: [
        .library(name: "SherpaOnnx", targets: ["SherpaOnnx"])
    ],
    dependencies: [
        .package(url: "https://github.com/k2-fsa/sherpa-onnx.git", from: "1.12.0")
    ],
    targets: [
        .target(
            name: "SherpaOnnx",
            dependencies: ["SherpaOnnx"],
            path: "Sources",
            resources: [
                .process("Models")
            ]
        )
    ]
)
```

## æ€§èƒ½ä¼˜åŒ–

### 1. éŸ³é¢‘å¤„ç†ä¼˜åŒ–

```swift
// ä½¿ç”¨åˆé€‚çš„ç¼“å†²åŒºå¤§å°
let optimalBufferSize: AVAudioFrameCount = 4096

// é™ä½å»¶è¿Ÿ
inputNode.installTap(
    onBus: 0,
    bufferSize: optimalBufferSize,
    format: recordingFormat
) { buffer, _ in
    // å¤„ç†éŸ³é¢‘
}

// åå°å¤„ç†è¯†åˆ«
DispatchQueue.global(qos: .userInteractive).async {
    self.recognizer.decode()
}
```

### 2. å†…å­˜ç®¡ç†

```swift
class SpeechRecognizer {
    private var recognizer: SherpaOnnxRecognizer?

    deinit {
        // æ¸…ç†èµ„æº
        recognizer = nil
        audioEngine?.stop()
        audioEngine = nil
    }

    func reset() {
        // é‡ç½®è¯†åˆ«å™¨çŠ¶æ€
        recognizer?.reset()
    }
}
```

### 3. æ¨¡å‹ä¼˜åŒ–

```swift
// ä½¿ç”¨é‡åŒ–æ¨¡å‹
func getQuantizedModelConfig() -> SherpaOnnxOnlineModelConfig {
    // ä½¿ç”¨ .int8 æ¨¡å‹
    let encoder = getResource("encoder.int8", "onnx")
    let decoder = getResource("decoder.int8", "onnx")

    // é…ç½®
    return sherpaOnnxOnlineModelConfig(
        tokens: tokens,
        paraformer: sherpaOnnxOnlineParaformerModelConfig(
            encoder: encoder,
            decoder: decoder
        ),
        numThreads: 1,  // å‡å°‘çº¿ç¨‹æ•°
        modelType: "paraformer"
    )
}
```

## éƒ¨ç½²å’Œå‘å¸ƒ

### 1. App Store é…ç½®

```swift
// åœ¨ Xcode ä¸­è®¾ç½®ï¼š
// - Deployment Target: iOS 13.0+
// - Architectures: arm64
// - Valid Architectures: arm64
// - Build Active Architecture Only: Debug = YES, Release = NO
```

### 2. æ¨¡å‹æ–‡ä»¶å¤„ç†

```swift
// ä½¿ç”¨ Asset Catalog æˆ– Bundle Resources
// é¿å…æ¨¡å‹æ–‡ä»¶è¢«å‹ç¼©
// å¯ç”¨ "On Demand Resources" å‡å°åº”ç”¨ä½“ç§¯

// åŠ¨æ€ä¸‹è½½æ¨¡å‹
func downloadModelIfNeeded() async {
    let modelURL = URL(string: "https://example.com/model.onnx")!
    let destination = getDocumentsDirectory().appendingPathComponent("model.onnx")

    // æ£€æŸ¥æœ¬åœ°æ˜¯å¦å­˜åœ¨
    if FileManager.default.fileExists(atPath: destination.path) {
        return
    }

    // ä¸‹è½½æ¨¡å‹
    let (data, _) = try await URLSession.shared.data(from: modelURL)
    try data.write(to: destination)
}
```

### 3. æ€§èƒ½ç›‘æ§

```swift
import os.log

class PerformanceMonitor {
    private let logger = Logger(subsystem: "com.app.sherpaonnx", category: "Performance")

    func measureRecognitionTime<T>(operation: () -> T) -> T {
        let startTime = CFAbsoluteTimeGetCurrent()
        let result = operation()
        let timeElapsed = CFAbsoluteTimeGetCurrent() - startTime

        logger.info("Recognition took \(timeElapsed * 1000, privacy: .public) ms")

        return result
    }
}
```

## æµ‹è¯•ç­–ç•¥

### 1. å•å…ƒæµ‹è¯•

```swift
import XCTest
@testable import SherpaOnnx

class SherpaOnnxTests: XCTestCase {
    func testModelLoading() {
        let config = getTestModelConfig()
        let recognizer = SherpaOnnxRecognizer(config: &config)
        XCTAssertNotNil(recognizer)
    }

    func testAudioProcessing() {
        let testData = generateTestAudio()
        let result = processAudio(testData)
        XCTAssertFalse(result.isEmpty)
    }
}
```

### 2. UI æµ‹è¯•

```swift
class SherpaOnnxUITests: XCTestCase {
    func testVoiceRecognitionFlow() throws {
        let app = XCUIApplication()
        app.launch()

        // ç‚¹å‡»å¼€å§‹æŒ‰é’®
        app.buttons["å¼€å§‹"].tap()

        // ç­‰å¾…è¯†åˆ«ç»“æœ
        let resultText = app.textViews["results"]
        let exists = resultText.waitForExistence(timeout: 10)
        XCTAssertTrue(exists)
    }
}
```

## å¸¸è§é—®é¢˜ (FAQ)

### Q1: è¯†åˆ«å»¶è¿Ÿè¿‡é«˜ï¼Ÿ
A: è§£å†³æ–¹æ¡ˆï¼š
- å‡å°éŸ³é¢‘ç¼“å†²åŒºå¤§å°
- ä½¿ç”¨æ›´å°çš„æ¨¡å‹
- å¯ç”¨ VAD ç«¯ç‚¹æ£€æµ‹

### Q2: å†…å­˜å ç”¨è¿‡å¤§ï¼Ÿ
A: ä¼˜åŒ–æ–¹æ³•ï¼š
```swift
// ä½¿ç”¨å¼±å¼•ç”¨é¿å…å¾ªç¯å¼•ç”¨
audioEngine?.inputNode.installTap { [weak self] buffer, _ in
    // å¤„ç†éŸ³é¢‘
}

// åŠæ—¶é‡Šæ”¾èµ„æº
deinit {
    audioEngine?.stop()
    audioEngine?.inputNode.removeTap(onBus: 0)
}
```

### Q3: æ¨¡å‹æ–‡ä»¶å¤ªå¤§ï¼Ÿ
A: è§£å†³æ–¹æ¡ˆï¼š
- ä½¿ç”¨é‡åŒ–æ¨¡å‹
- å®ç°åŠ¨æ€ä¸‹è½½
- å‹ç¼©æ¨¡å‹æ–‡ä»¶

### Q4: å®æ—¶è¯†åˆ«ä¸­æ–­ï¼Ÿ
A: æ£€æŸ¥ï¼š
- éŸ³é¢‘ä¼šè¯é…ç½®
- åå°æƒé™
- å†…å­˜ä½¿ç”¨æƒ…å†µ

### Q5: éº¦å…‹é£æƒé™è¢«æ‹’ç»ï¼Ÿ
A: å¤„ç†æ–¹å¼ï¼š
```swift
func checkMicrophonePermission() {
    AVAudioSession.sharedInstance().requestRecordPermission { granted in
        if !granted {
            // æ˜¾ç¤ºæƒé™è¯´æ˜
            DispatchQueue.main.async {
                let alert = UIAlertController(
                    title: "éœ€è¦éº¦å…‹é£æƒé™",
                    message: "è¯·åœ¨è®¾ç½®ä¸­å…è®¸è®¿é—®éº¦å…‹é£",
                    preferredStyle: .alert
                )

                alert.addAction(UIAlertAction(
                    title: "å»è®¾ç½®",
                    style: .default
                ) { _ in
                    if let settings = URL(string: UIApplication.openSettingsURLString) {
                        UIApplication.shared.open(settings)
                    }
                })

                self.present(alert, animated: true)
            }
        }
    }
}
```

## ç›¸å…³æ–‡ä»¶æ¸…å•

### ç¤ºä¾‹åº”ç”¨
- `ios-swiftui/SherpaOnnx/` - åŸºç¡€è¯­éŸ³è¯†åˆ«
- `ios-swiftui/SherpaOnnx2Pass/` - ä¸¤éè¯†åˆ«
- `ios-swiftui/SherpaOnnxTts/` - è¯­éŸ³åˆæˆ
- `ios-swiftui/SherpaOnnxSubtitle/` - å­—å¹•ç”Ÿæˆ
- `ios-swiftui/SherpaOnnxLangID/` - è¯­è¨€è¯†åˆ«

### æ ¸å¿ƒæ–‡ä»¶
- `Model.swift` - æ¨¡å‹é…ç½®
- `ViewModel.swift` - ä¸šåŠ¡é€»è¾‘
- `ContentView.swift` - SwiftUI ç•Œé¢
- `ViewController.swift` - UIKit ç•Œé¢

### æ„å»ºæ–‡ä»¶
- `Package.swift` - Swift Package é…ç½®
- `.xcodeproj/` - Xcode é¡¹ç›®æ–‡ä»¶
- `Info.plist` - åº”ç”¨é…ç½®

## å˜æ›´è®°å½•

### 2025-12-10 07:48:28
- ğŸ“ åˆ›å»º iOS é›†æˆæ–‡æ¡£
- ğŸ“± æ·»åŠ  SwiftUI å’Œ UIKit ç¤ºä¾‹
- ğŸ¯ åŒ…å«å®Œæ•´çš„ API ä½¿ç”¨è¯´æ˜
- ğŸ”§ è¡¥å……æ€§èƒ½ä¼˜åŒ–å’Œæ•…éšœæ’é™¤

---

*ç›¸å…³æ–‡ä»¶ï¼š[Swift ç¤ºä¾‹](../swift-api-examples/CLAUDE.md) | [æ„å»ºç³»ç»Ÿ](../build.sh) | [æ¨¡å‹ä¸‹è½½](https://github.com/k2-fsa/sherpa-onnx/releases)*