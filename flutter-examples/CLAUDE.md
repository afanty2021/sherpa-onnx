[æ ¹ç›®å½•](../CLAUDE.md) > **flutter-examples**

# Flutter ç¤ºä¾‹

> æ›´æ–°æ—¶é—´ï¼š2025-12-10 07:48:28

## æ¨¡å—èŒè´£

Flutter ç¤ºä¾‹æ¨¡å—å±•ç¤ºäº†å¦‚ä½•åœ¨è·¨å¹³å°ç§»åŠ¨åº”ç”¨ä¸­é›†æˆ Sherpa-ONNX çš„è¯­éŸ³å¤„ç†åŠŸèƒ½ã€‚è¿™äº›ç¤ºä¾‹ä½¿ç”¨ Dart è¯­è¨€å’Œ Flutter æ¡†æ¶ï¼Œæä¾›äº†åœ¨ iOSã€Androidã€Windowsã€macOS å’Œ Linux ä¸Šä¸€è‡´çš„è¯­éŸ³ AI ä½“éªŒã€‚

## ç¤ºä¾‹åº”ç”¨æ¦‚è§ˆ

### 1. å®æ—¶è¯­éŸ³è¯†åˆ« (Streaming ASR)
**è·¯å¾„**: `streaming_asr/`

**åŠŸèƒ½ç‰¹ç‚¹**:
- å®æ—¶éº¦å…‹é£è¾“å…¥å¤„ç†
- æµå¼è¯­éŸ³è¯†åˆ«
- å¯è§†åŒ–è¯†åˆ«ç»“æœ
- æ”¯æŒå¤šç§æ¨¡å‹åˆ‡æ¢

**æ ¸å¿ƒæ–‡ä»¶**:
- `lib/main.dart` - åº”ç”¨å…¥å£
- `lib/streaming_asr.dart` - è¯†åˆ«ç•Œé¢
- `lib/online_model.dart` - æ¨¡å‹é…ç½®
- `lib/utils.dart` - å·¥å…·å‡½æ•°

### 2. è¯­éŸ³åˆæˆ (TTS)
**è·¯å¾„**: `tts/`

**åŠŸèƒ½ç‰¹ç‚¹**:
- æ–‡æœ¬è½¬è¯­éŸ³
- å¤šç§ TTS æ¨¡å‹æ”¯æŒ
- éŸ³é¢‘æ’­æ”¾åŠŸèƒ½
- Isolate éš”ç¦»å¤„ç†

**æ ¸å¿ƒæ–‡ä»¶**:
- `lib/tts.dart` - TTS ä¸»ç•Œé¢
- `lib/isolate_tts.dart` - åå° TTS å¤„ç†
- `lib/offline_model.dart` - TTS æ¨¡å‹é…ç½®

### 3. éæµå¼ VAD+ASR
**è·¯å¾„**: `non_streaming_vad_asr/`

**åŠŸèƒ½ç‰¹ç‚¹**:
- VADï¼ˆè¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼‰
- éæµå¼æ–‡ä»¶è¯†åˆ«
- æ‰¹å¤„ç†éŸ³é¢‘æ–‡ä»¶

## å…¥å£ä¸å¯åŠ¨

### ç¯å¢ƒè¦æ±‚
- **Flutter SDK**: 3.0+
- **Dart SDK**: 2.17+
- **å¹³å°**: iOS 13+, Android API 21+

### å¿«é€Ÿå¼€å§‹

```bash
# 1. å…‹éš†ä»“åº“
git clone https://github.com/k2-fsa/sherpa-onnx.git
cd sherpa-onnx/flutter-examples/streaming_asr

# 2. å®‰è£…ä¾èµ–
flutter pub get

# 3. è¿è¡Œåº”ç”¨
flutter run

# 4. æŒ‡å®šå¹³å°è¿è¡Œ
flutter run -d ios
flutter run -d android
flutter run -d windows
flutter run -d macos
```

### ä¾èµ–é…ç½®

åœ¨ `pubspec.yaml` ä¸­æ·»åŠ ï¼š
```yaml
dependencies:
  flutter:
    sdk: flutter

  # Sherpa-ONNX Flutter æ’ä»¶
  sherpa_onnx: ^1.0.0

  # éŸ³é¢‘å¤„ç†
  record: ^5.0.4
  audioplayers: ^5.2.1

  # è·¯å¾„å’Œæ–‡ä»¶
  path_provider: ^2.1.1
  path: ^1.8.3

  # çŠ¶æ€ç®¡ç†
  provider: ^6.1.1
```

## å¯¹å¤–æ¥å£

### 1. å®æ—¶è¯­éŸ³è¯†åˆ«æ¥å£

#### åˆå§‹åŒ–è¯†åˆ«å™¨
```dart
import 'package:sherpa_onnx/sherpa_onnx.dart' as sherpa_onnx;

// åˆ›å»ºåœ¨çº¿è¯†åˆ«å™¨
Future<sherpa_onnx.OnlineRecognizer> createOnlineRecognizer() async {
  // é…ç½®æ¨¡å‹
  final modelConfig = sherpa_onnx.OnlineModelConfig(
    zipformer: sherpa_onnx.OnlineZipformerModelConfig(
      encoder: 'models/encoder.onnx',
      decoder: 'models/decoder.onnx',
      joiner: 'models/joiner.onnx',
    ),
    tokens: 'models/tokens.txt',
    numThreads: 2,
    provider: 'cpu',
    debug: false,
  );

  // é…ç½®è¯†åˆ«å™¨
  final config = sherpa_onnx.OnlineRecognizerConfig(
    model: modelConfig,
    featConfig: sherpa_onnx.FeatureConfig(
      sampleRate: 16000,
      featureDim: 80,
    ),
    endpointConfig: sherpa_onnx.EndpointConfig(
      rule1MinTrailingSilence: 2.4,
      rule2MinTrailingSilence: 0.8,
      rule3MinUtteranceLength: 30,
    ),
  );

  return sherpa_onnx.OnlineRecognizer(config);
}
```

#### å®æ—¶éŸ³é¢‘å¤„ç†
```dart
class _StreamingAsrScreenState extends State<StreamingAsrScreen> {
  late final AudioRecorder _audioRecorder;
  sherpa_onnx.OnlineRecognizer? _recognizer;
  sherpa_onnx.OnlineStream? _stream;

  @override
  void initState() {
    super.initState();
    _audioRecorder = AudioRecorder();

    // åˆå§‹åŒ–è¯†åˆ«å™¨
    _initRecognizer();
  }

  Future<void> _startRecording() async {
    // é…ç½®å½•éŸ³
    const config = RecordConfig(
      encoder: AudioEncoder.pcm16bits,
      sampleRate: 16000,
      numChannels: 1,
    );

    // å¼€å§‹å½•éŸ³æµ
    final stream = await _audioRecorder.startStream(config);

    // å¤„ç†éŸ³é¢‘æ•°æ®
    stream.listen((data) {
      final samples = convertBytesToFloat32(data);

      // æäº¤ç»™è¯†åˆ«å™¨
      _stream?.acceptWaveform(
        samples: samples,
        sampleRate: 16000,
      );

      // è·å–è¯†åˆ«ç»“æœ
      while (_recognizer?.isReady(_stream) == true) {
        _recognizer?.decode(_stream);
      }

      final result = _recognizer?.getResult(_stream);
      if (result?.text.isNotEmpty == true) {
        setState(() {
          _textController.text = result!.text;
        });
      }
    });
  }
}
```

### 2. è¯­éŸ³åˆæˆæ¥å£

#### TTS åˆå§‹åŒ–
```dart
import 'package:sherpa_onnx/sherpa_onnx.dart' as sherpa_onnx;

Future<sherpa_onnx.OfflineTts> createTts() async {
  // é…ç½® VITS æ¨¡å‹
  final modelConfig = sherpa_onnx.OfflineTtsModelConfig(
    vits: sherpa_onnx.OfflineTtsVitsModelConfig(
      model: 'models/vits.onnx',
      lexicon: 'models/lexicon.txt',
    ),
    tokens: 'models/tokens.txt',
    numThreads: 1,
    debug: true,
  );

  // é…ç½® TTS
  final config = sherpa_onnx.OfflineTtsConfig(
    model: modelConfig,
    ruleFsts: '',
    maxNumSentences: 2,
  );

  return sherpa_onnx.OfflineTts(config);
}
```

#### æ–‡æœ¬è½¬è¯­éŸ³
```dart
class TtsScreen extends StatefulWidget {
  @override
  _TtsScreenState createState() => _TtsScreenState();
}

class _TtsScreenState extends State<TtsScreen> {
  sherpa_onnx.OfflineTts? _tts;
  final AudioPlayer _player = AudioPlayer();

  Future<void> _generateSpeech(String text) async {
    // ç”Ÿæˆè¯­éŸ³
    final audio = _tts?.generate(
      text: text,
      speakerId: 0,
      speed: 1.0,
    );

    if (audio != null) {
      // ä¿å­˜ä¸´æ—¶æ–‡ä»¶
      final tempDir = await getTemporaryDirectory();
      final file = File('${tempDir.path}/output.wav');
      await file.writeAsBytes(audio.samples);

      // æ’­æ”¾éŸ³é¢‘
      await _player.play(DeviceFileSource(file.path));
    }
  }
}
```

### 3. Isolate éš”ç¦»å¤„ç†

#### ä½¿ç”¨ Isolate é¿å…é˜»å¡ UI
```dart
import 'dart:isolate';

// TTS Isolate å…¥å£ç‚¹
void _ttsIsolateEntry(SendPort sendPort) {
  final port = ReceivePort();
  sendPort.send(port.sendPort);

  port.listen((message) async {
    if (message is Map<String, dynamic>) {
      final text = message['text'] as String;
      final replyPort = message['replyPort'] as SendPort;

      // åœ¨ Isolate ä¸­ç”Ÿæˆè¯­éŸ³
      final audio = await generateTtsInIsolate(text);

      replyPort.send(audio);
    }
  });
}

// ä¸»ç±»ä¸­ä½¿ç”¨ Isolate
class IsolateTtsView extends StatefulWidget {
  @override
  _IsolateTtsViewState createState() => _IsolateTtsViewState();
}

class _IsolateTtsViewState extends State<IsolateTtsView> {
  Isolate? _ttsIsolate;
  SendPort? _ttsSendPort;

  Future<void> _initIsolate() async {
    final receivePort = ReceivePort();
    _ttsIsolate = await Isolate.spawn(_ttsIsolateEntry, receivePort.sendPort);

    _ttsSendPort = await receivePort.first as SendPort;
  }

  Future<void> _generateSpeechIsolate(String text) async {
    final responsePort = ReceivePort();

    _ttsSendPort?.send({
      'text': text,
      'replyPort': responsePort.sendPort,
    });

    // ç­‰å¾…ç»“æœ
    final audio = await responsePort.first;

    // æ’­æ”¾éŸ³é¢‘
    _playAudio(audio);
  }
}
```

## å…³é”®ä¾èµ–ä¸é…ç½®

### Flutter æ’ä»¶ä¾èµ–

```yaml
# pubspec.yaml
dependencies:
  sherpa_onnx: ^1.0.0          # Sherpa-ONNX Flutter æ’ä»¶

  # éŸ³é¢‘å½•åˆ¶
  record: ^5.0.4               # è·¨å¹³å°å½•éŸ³

  # éŸ³é¢‘æ’­æ”¾
  audioplayers: ^5.2.1         # éŸ³é¢‘æ’­æ”¾å™¨
  just_audio: ^0.9.36          # å¦ä¸€ä¸ªéŸ³é¢‘æ’­æ”¾é€‰é¡¹

  # æ–‡ä»¶ç³»ç»Ÿ
  path_provider: ^2.1.1        # è·¯å¾„ç®¡ç†
  path: ^1.8.3                 # è·¯å¾„æ“ä½œ

  # å·¥å…·åº“
  permission_handler: ^11.0.1  # æƒé™ç®¡ç†
  file_picker: ^6.1.1          # æ–‡ä»¶é€‰æ‹©
```

### å¹³å°ç‰¹å®šé…ç½®

#### Android (`android/app/src/main/AndroidManifest.xml`)
```xml
<!-- éº¦å…‹é£æƒé™ -->
<uses-permission android:name="android.permission.RECORD_AUDIO" />
<uses-permission android:name="android.permission.WRITE_EXTERNAL_STORAGE" />
<uses-permission android:name="android.permission.READ_EXTERNAL_STORAGE" />

<!-- ç½‘ç»œæƒé™ï¼ˆä¸‹è½½æ¨¡å‹ï¼‰ -->
<uses-permission android:name="android.permission.INTERNET" />
```

#### iOS (`ios/Runner/Info.plist`)
```xml
<key>NSMicrophoneUsageDescription</key>
<string>æ­¤åº”ç”¨éœ€è¦è®¿é—®éº¦å…‹é£è¿›è¡Œè¯­éŸ³è¯†åˆ«</string>

<key>NSDocumentsFolderUsageDescription</key>
<string>æ­¤åº”ç”¨éœ€è¦è®¿é—®æ–‡æ¡£æ–‡ä»¶å¤¹åŠ è½½éŸ³é¢‘æ–‡ä»¶</string>
```

#### Windows (`windows/runner/CMakeLists.txt`)
```cmake
# æ·»åŠ  Sherpa-ONNX ä¾èµ–
find_package(sherpa-onnx REQUIRED CONFIG)

target_link_libraries(${BINARY_NAME} PRIVATE
  sherpa-onnx::sherpa-onnx
  flutter
  flutter_wrapper_app
)
```

### æ¨¡å‹æ–‡ä»¶ç®¡ç†

```dart
class ModelManager {
  static Future<String> _downloadModel(String url, String filename) async {
    final directory = await getApplicationDocumentsDirectory();
    final file = File('${directory.path}/$filename');

    if (await file.exists()) {
      return file.path;
    }

    final request = HttpRequest.request(
      url,
      method: 'GET',
    );

    final response = await request;
    await file.writeAsBytes(response.responseBytes);

    return file.path;
  }

  static Future<void> initializeModels() async {
    // ä¸‹è½½ ASR æ¨¡å‹
    final asrModelUrl = 'https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-zh-14M-2023-02-23.tar.bz2';
    await _downloadModel(asrModelUrl, 'asr_model.onnx');

    // ä¸‹è½½ TTS æ¨¡å‹
    final ttsModelUrl = 'https://github.com/k2-fsa/sherpa-onnx/releases/download/tts-models/vits-piper-zh_CN-huayan-medium.tar.bz2';
    await _downloadModel(ttsModelUrl, 'tts_model.onnx');
  }
}
```

## æ€§èƒ½ä¼˜åŒ–

### 1. éŸ³é¢‘ç¼“å†²åŒºä¼˜åŒ–

```dart
class AudioProcessor {
  static const int _bufferSize = 4096;
  static const int _sampleRate = 16000;

  late final List<double> _audioBuffer;
  int _bufferIndex = 0;

  void processAudioChunk(List<int> chunk) {
    final samples = convertBytesToFloat32(chunk);

    for (final sample in samples) {
      _audioBuffer[_bufferIndex] = sample;
      _bufferIndex++;

      if (_bufferIndex >= _bufferSize) {
        // å¤„ç†æ»¡ç¼“å†²åŒº
        _processBuffer();
        _bufferIndex = 0;
      }
    }
  }
}
```

### 2. å†…å­˜ç®¡ç†

```dart
class RecognizerManager {
  sherpa_onnx.OnlineRecognizer? _recognizer;

  // ä½¿ç”¨èµ„æºæ± ç®¡ç†è¯†åˆ«å™¨
  final List<sherpa_onnx.OnlineRecognizer> _pool = [];
  final int _maxPoolSize = 3;

  sherpa_onnx.OnlineRecognizer getRecognizer() {
    if (_pool.isNotEmpty) {
      return _pool.removeLast();
    }

    return _createNewRecognizer();
  }

  void returnRecognizer(sherpa_onnx.OnlineRecognizer recognizer) {
    if (_pool.length < _maxPoolSize) {
      _pool.add(recognizer);
    } else {
      recognizer.dispose();
    }
  }
}
```

### 3. UI å“åº”æ€§ä¼˜åŒ–

```dart
// ä½¿ç”¨ Compute åˆ†ç¦»è®¡ç®—å¯†é›†å‹ä»»åŠ¡
Future<List<double>> computeAudioFeatures(List<double> audioData) async {
  return await compute(_extractFeatures, audioData);
}

// Isolate ä¸­çš„è®¡ç®—å‡½æ•°
List<double> _extractFeatures(List<double> audioData) {
  // æ‰§è¡Œç‰¹å¾æå–
  // ...
  return features;
}
```

## æµ‹è¯•ç­–ç•¥

### 1. å•å…ƒæµ‹è¯•

```dart
// test/asr_test.dart
import 'package:flutter_test/flutter_test.dart';
import 'package:sherpa_onnx/sherpa_onnx.dart';

void main() {
  group('ASR Tests', () {
    test('Model loading', () async {
      final recognizer = await createTestRecognizer();
      expect(recognizer, isNotNull);
    });

    test('Audio processing', () {
      final testData = generateTestAudio();
      final result = processAudio(testData);
      expect(result, isNotEmpty);
    });
  });
}
```

### 2. Widget æµ‹è¯•

```dart
// test/widget_test.dart
import 'package:flutter/material.dart';
import 'package:flutter_test/flutter_test.dart';

void main() {
  testWidgets('ASR UI test', (WidgetTester tester) async {
    await tester.pumpWidget(MyApp());

    // æŸ¥æ‰¾å¼€å§‹æŒ‰é’®
    final startButton = find.widgetWithText(ElevatedButton, 'Start');
    expect(startButton, findsOneWidget);

    // ç‚¹å‡»æŒ‰é’®
    await tester.tap(startButton);
    await tester.pump();

    // éªŒè¯çŠ¶æ€å˜åŒ–
    expect(find.text('Recording...'), findsOneWidget);
  });
}
```

### 3. é›†æˆæµ‹è¯•

```dart
// integration_test/app_test.dart
import 'package:flutter/material.dart';
import 'package:flutter_test/flutter_test.dart';
import 'package:integration_test/integration_test.dart';

void main() {
  IntegrationTestWidgetsFlutterBinding.ensureInitialized();

  testWidgets('End-to-end ASR flow', (WidgetTester tester) async {
    app.main();
    await tester.pumpAndSettle();

    // æ‰§è¡Œå®Œæ•´è¯†åˆ«æµç¨‹
    await tester.tap(find.byKey(Key('start_button')));
    await tester.pumpAndSettle(Duration(seconds: 5));

    // éªŒè¯ç»“æœ
    expect(find.byType(Text), findsWidgets);
  });
}
```

## éƒ¨ç½²æŒ‡å—

### 1. Android æ‰“åŒ…

```bash
# ç”Ÿæˆç­¾åå¯†é’¥
keytool -genkey -v -keystore ~/upload-keystore.jks -keyalg RSA -keysize 2048 -validity 10000 -alias upload

# é…ç½®ç­¾å (android/key.properties)
storePassword=myStorePassword
keyPassword=myKeyPassword
keyAlias=myKeyAlias
storeFile=myStoreFileLocation

# æ„å»º Release APK
flutter build apk --release

# æ„å»º AAB
flutter build appbundle --release
```

### 2. iOS æ‰“åŒ…

```bash
# é…ç½® iOS è¯ä¹¦å’Œæè¿°æ–‡ä»¶
open ios/Runner.xcworkspace

# æ„å»º
flutter build ios --release

# ä½¿ç”¨ Xcode Archive
# Product > Archive
```

### 3. æ¨¡å‹æ–‡ä»¶ä¼˜åŒ–

```dart
class AssetBundleHelper {
  static Future<void> preloadModels() async {
    // é¢„åŠ è½½æ¨¡å‹åˆ°å†…å­˜
    final manifest = await DefaultAssetBundle.of(context).loadString('AssetManifest.json');
    final assets = json.decode(manifest) as Map<String, dynamic>;

    final modelAssets = assets.keys
        .where((path) => path.contains('models'))
        .toList();

    for (final asset in modelAssets) {
      await DefaultAssetBundle.of(context).load(asset);
    }
  }
}
```

## å¸¸è§é—®é¢˜ (FAQ)

### Q1: Flutter åº”ç”¨å¯åŠ¨æ…¢ï¼Ÿ
A: ä¼˜åŒ–æ–¹æ¡ˆï¼š
- å»¶è¿ŸåŠ è½½æ¨¡å‹
- ä½¿ç”¨ Isolate é¢„åŠ è½½
- å‹ç¼©æ¨¡å‹æ–‡ä»¶

### Q2: å®æ—¶è¯†åˆ«å¡é¡¿ï¼Ÿ
A: è§£å†³æ–¹æ¡ˆï¼š
- è°ƒæ•´ç¼“å†²åŒºå¤§å°
- ä½¿ç”¨ compute åˆ†ç¦»è®¡ç®—
- ä¼˜åŒ–éŸ³é¢‘å¤„ç†æµç¨‹

### Q3: Android æƒé™é—®é¢˜ï¼Ÿ
A: å¤„ç†æ–¹å¼ï¼š
```dart
import 'package:permission_handler/permission_handler.dart';

Future<void> requestPermissions() async {
  final status = await Permission.microphone.request();
  if (status.isDenied) {
    // æ˜¾ç¤ºæƒé™è¯´æ˜
    openAppSettings();
  }
}
```

### Q4: æ¨¡å‹æ–‡ä»¶å¤ªå¤§ï¼Ÿ
A: è§£å†³æ–¹æ¡ˆï¼š
- ä½¿ç”¨åŠ¨æ€ä¸‹è½½
- å®ç°æ¨¡å‹å‹ç¼©
- æŒ‰éœ€åŠ è½½ä¸åŒè¯­è¨€æ¨¡å‹

### Q5: iOS åå°å½•éŸ³é—®é¢˜ï¼Ÿ
A: é…ç½® Info.plistï¼š
```xml
<key>UIBackgroundModes</key>
<array>
    <string>audio</string>
</array>
```

## ç›¸å…³æ–‡ä»¶æ¸…å•

### ç¤ºä¾‹åº”ç”¨
- `streaming_asr/` - å®æ—¶è¯­éŸ³è¯†åˆ«
- `tts/` - è¯­éŸ³åˆæˆ
- `non_streaming_vad_asr/` - VAD+ASR ç»„åˆ

### æ ¸å¿ƒæ–‡ä»¶
- `lib/main.dart` - åº”ç”¨å…¥å£
- `lib/asr.dart` - ASR å®ç°
- `lib/tts.dart` - TTS å®ç°
- `lib/model.dart` - æ¨¡å‹é…ç½®
- `pubspec.yaml` - ä¾èµ–é…ç½®

### å¹³å°é…ç½®
- `android/` - Android é…ç½®
- `ios/` - iOS é…ç½®
- `windows/` - Windows é…ç½®
- `macos/` - macOS é…ç½®
- `linux/` - Linux é…ç½®

## å˜æ›´è®°å½•

### 2025-12-10 07:48:28
- ğŸ“ åˆ›å»º Flutter ç¤ºä¾‹æ–‡æ¡£
- ğŸ“± æ·»åŠ è·¨å¹³å°æ”¯æŒè¯´æ˜
- ğŸ”§ è¡¥å……æ€§èƒ½ä¼˜åŒ–æŠ€å·§
- ğŸ’¡ æä¾›éƒ¨ç½²å’Œæµ‹è¯•æŒ‡å—

---

*ç›¸å…³æ–‡ä»¶ï¼š[Flutter æ’ä»¶](../flutter/sherpa_onnx_ios/CLAUDE.md) | [Android é›†æˆ](../android/CLAUDE.md) | [iOS é›†æˆ](../ios/CLAUDE.md)*